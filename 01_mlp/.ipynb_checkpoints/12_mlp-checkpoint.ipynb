{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6250cb23a4356d34a1780ae02290c528",
     "grade": false,
     "grade_id": "cell-0a8316b039d048ad",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Number of points for this notebook:</b> 1\n",
    "<br>\n",
    "<b>Deadline:</b> March 2, 2020 (Monday). 23:00\n",
    "</div>\n",
    "\n",
    "# Exercise 1.2. Multilayer perceptron\n",
    "\n",
    "The goal of this exercise is to get familiar with the basics of PyTorch and train a multilayer perceptron (MLP) model.\n",
    "\n",
    "If you are not familiar with PyTorch, there is a number of good tutorials [here](https://pytorch.org/tutorials/index.html). We recommend the following ones:\n",
    "* [What is PyTorch?](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py)\n",
    "* [Autograd: Automatic Differentiation](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py)\n",
    "* [Learning PyTorch with Examples](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html)\n",
    "* [Neural Networks](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = True  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65e2970339980ef7d85c3754662c4ee8",
     "grade": true,
     "grade_id": "evaluation_settings",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# During evaluation, this cell sets skip_training to True\n",
    "# skip_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import tools\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data directory is /coursedata\n"
     ]
    }
   ],
   "source": [
    "# When running on your own computer, you can specify the data directory by:\n",
    "# data_dir = tools.select_data_dir('/your/local/data/directory')\n",
    "data_dir = tools.select_data_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select device which you are going to use for training\n",
    "#device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc5c0195206dae40876fe429916217c4",
     "grade": false,
     "grade_id": "cell-70232a39ccf9c751",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    # The models are always evaluated on CPU\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b2a4dbb00c7cb91e341fc07f0c9e819e",
     "grade": false,
     "grade_id": "cell-ce13efdf413792bd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Data\n",
    "\n",
    "We will use the same *winequality* dataset as in the logistic regression notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f67d03b89cc3b01300a59878d625df1f",
     "grade": false,
     "grade_id": "cell-c1dddacb4674e7d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5197, 11]) torch.Size([5197])\n"
     ]
    }
   ],
   "source": [
    "trainset = data.WineQuality(data_dir, train=True, normalize=False)\n",
    "train_inputs, train_targets = trainset.tensors\n",
    "print(train_inputs.shape, train_targets.shape)\n",
    "\n",
    "testset = data.WineQuality(data_dir, train=False, normalize=False)\n",
    "test_inputs, test_targets = testset.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "88c8a81545f4583ece106fbc9b828048",
     "grade": false,
     "grade_id": "cell-06e53b02efa1a412",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Convert to a binary classification problem\n",
    "train_targets = (train_targets >= 7).float().view(-1, 1)  \n",
    "test_targets = (test_targets >= 7).float().view(-1, 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f20ceffcb544b9a2d45932b0109cfae3",
     "grade": false,
     "grade_id": "cell-293d291c8a8f705b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Normalize inputs to zero mean and unit variance\n",
    "mean = train_inputs.mean(dim=0)\n",
    "std = train_inputs.std(dim=0)\n",
    "scaler = lambda x: (x - mean.to(x.device)) / std.to(x.device)\n",
    "\n",
    "train_inputs = scaler(train_inputs)\n",
    "test_inputs = scaler(test_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "77371a24f68d60f5e62232e50c62ef58",
     "grade": false,
     "grade_id": "cell-76070c68689a5242",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Multilayer perceptron (MLP) network with two hidden layers\n",
    "\n",
    "We will create a simple multilayer perceptron (MLP) network. The model has\n",
    "- input dimensionality 11\n",
    "- one hidden layer with 200 units with ReLU nonlinearity\n",
    "- one hidden layer with 100 units with ReLU nonlinearity\n",
    "- linear output layer with output dimensionality 1 and sigmoid nonlinearity.\n",
    "\n",
    "Hints:\n",
    "* You may want to look at [this tutorial](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py) for reference.\n",
    "* You can use [`nn.Linear`](https://pytorch.org/docs/stable/nn.html?highlight=nn%20linear#torch.nn.Linear)\n",
    "module to define the fully-connected layers of the MLP.\n",
    "* Simple architectures are usually created using module [`torch.nn.Sequential`](https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential). You do not have to use this module in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8368525a3069c108c6279434641013d",
     "grade": false,
     "grade_id": "MLP",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_inputs=11):\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        super(MLP, self).__init__()\n",
    "        self.w1 = nn.Linear(n_inputs, 200, bias=True)\n",
    "        self.w2 = nn.Linear(200, 100, bias=True)\n",
    "        self.w3 = nn.Linear(100, 1, bias=True)\n",
    "        \n",
    "#         raise NotImplementedError()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x of shape (n_samples, n_inputs): Model inputs.\n",
    "        \n",
    "        Returns:\n",
    "          y of shape (n_samples, 1): Model outputs.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        out = torch.relu(self.w1(x))\n",
    "        out = torch.relu(self.w2(out))\n",
    "        out = torch.sigmoid(self.w3(out))\n",
    "        return out\n",
    "        \n",
    "#         raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1aab0398bc5e799ac2bb00cb032c233",
     "grade": false,
     "grade_id": "cell-1dcdd8e8bdecf07e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "# Let us create the network and make sure it can process a random input of the right shape\n",
    "def test_MLP_shapes():\n",
    "    n_inputs = 11\n",
    "    n_samples = 10\n",
    "    net = MLP()\n",
    "    y = net(torch.randn(n_samples, n_inputs))\n",
    "    assert y.shape == torch.Size([n_samples, 1]), f\"Bad y.shape={y.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_MLP_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bc2b5c803135818b43ccf74b6a92355b",
     "grade": false,
     "grade_id": "cell-70cbd420870116d7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Train the MLP network\n",
    "\n",
    "### Training loop\n",
    "\n",
    "Your task is to implement the training loop.\n",
    "You training loop should have the same steps as in the logistic regression notebook.\n",
    "\n",
    "Recommended hyperparameters:\n",
    "* [Adam optimizer](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam) with learning rate 0.01.\n",
    "* You can process the data in the full-batch model (computing the gradients using all training data).\n",
    "* Number of iterations (parameter updates): 2000.\n",
    "\n",
    "Hints:\n",
    "- We recommend you to print the classification accuracy during training. You can compute the accuracy using function `compute_accuracy`.\n",
    "- The accuracy on the training set should be close to 1.0 (the model overfits to the training data).\n",
    "The test accuracy should be above 0.84."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34ca5c4584adc251cbf5ee8d77e9da1d",
     "grade": false,
     "grade_id": "cell-a02ff8398db50351",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Compute the accuracy of the model on the given dataset\n",
    "def compute_accuracy(model, inputs, targets):\n",
    "    with torch.no_grad():\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = (model.forward(inputs) > 0.5).float()\n",
    "        accuracy = (outputs == targets).sum().float() / targets.numel()\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2093029bcb3af8e8fed294511ebf6ce7",
     "grade": false,
     "grade_id": "cell-70f3840f16dc60f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (w1): Linear(in_features=11, out_features=200, bias=True)\n",
       "  (w2): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (w3): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "model = MLP()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9024f113b9988967e9b44d29edff745",
     "grade": false,
     "grade_id": "cell-692ef1b990bd1bbc",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 0.6723265647888184, acc: 0.7436982989311218\n",
      "epoch: 101, loss: 0.2455398142337799, acc: 0.8901289105415344\n",
      "epoch: 201, loss: 0.20512372255325317, acc: 0.9020588994026184\n",
      "epoch: 301, loss: 0.09938793629407883, acc: 0.9590148329734802\n",
      "epoch: 401, loss: 0.04690491408109665, acc: 0.9894169569015503\n",
      "epoch: 501, loss: 0.03797384351491928, acc: 0.9924956560134888\n",
      "epoch: 601, loss: 0.023734984919428825, acc: 0.9976909756660461\n",
      "epoch: 701, loss: 0.01579287089407444, acc: 0.9994227290153503\n",
      "epoch: 801, loss: 0.010910815559327602, acc: 0.9996151328086853\n",
      "epoch: 901, loss: 0.007824904285371304, acc: 0.999807596206665\n"
     ]
    }
   ],
   "source": [
    "# Implement the training loop here\n",
    "if not skip_training:\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    criterion = nn.functional.binary_cross_entropy\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    for epoch in range(1000):\n",
    "        optim.zero_grad()\n",
    "        out = model(train_inputs)\n",
    "        loss = criterion(out, train_targets)\n",
    "        if epoch%100==0:\n",
    "            print(\"epoch: {}, loss: {}, acc: {}\".format(epoch+1, loss, compute_accuracy(model,train_inputs,train_targets)))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    \n",
    "#     raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "706c26d15f43b2f94b0b02eb2d01e792",
     "grade": false,
     "grade_id": "mlp_accuracy",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to save the model (type yes to confirm)? yes\n",
      "Model saved to 1_mlp.pth.\n"
     ]
    }
   ],
   "source": [
    "# Save the model to disk (the pth-files will be submitted automatically together with your notebook)\n",
    "if not skip_training:\n",
    "    tools.save_model(model, '1_mlp.pth')\n",
    "else:\n",
    "    model = MLP()\n",
    "    tools.load_model(model, '1_mlp.pth', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "796af2e43d0e4c5f471453a03dc4e45e",
     "grade": true,
     "grade_id": "test_accuracy",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.8584615588188171\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "accuracy = compute_accuracy(model, test_inputs, test_targets)\n",
    "print('Accuracy on test set:', accuracy.item())\n",
    "assert accuracy >= 0.84, 'MLP classifier has poor accuracy.'\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cefde213839fc24fdd9453cc2385f4d4",
     "grade": true,
     "grade_id": "test_MLP",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell tests MLP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
