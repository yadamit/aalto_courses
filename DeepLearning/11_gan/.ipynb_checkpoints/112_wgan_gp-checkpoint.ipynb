{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "HIxWHS0IACik",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eba08e6b37e7c559afeccf4cb8b27635",
     "grade": false,
     "grade_id": "cell-9aa58d6cac14c783",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Number of points for this notebook:</b> 2\n",
    "<br>\n",
    "<b>Deadline:</b> May 23, 2020 (Saturday) 23:00\n",
    "</div>\n",
    "\n",
    "# Exercise 11.2. Generative adversarial networks (GANs). WGAN-GP: Wasserstein GAN with gradient penalty\n",
    "\n",
    "The goal of this exercise is to get familiar with WGAN-GP: one of the most popular versions of GANs, which is relatively easy to train.\n",
    "\n",
    "The algorithm was introduced in the paper [Improved Training of Wasserstein GANs](https://arxiv.org/pdf/1704.00028.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LmVBXWBSACio"
   },
   "outputs": [],
   "source": [
    "skip_training = True  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "PwWCtdIvACi4",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67c33e7b0ef5b2539c31188a69d90430",
     "grade": true,
     "grade_id": "cell-170e509aea63f9e2",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# During evaluation, this cell sets skip_training to True\n",
    "# skip_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hik5Sh6-ACjF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as utils\n",
    "\n",
    "import tools\n",
    "import tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5053,
     "status": "ok",
     "timestamp": 1590245300960,
     "user": {
      "displayName": "Amit Yadav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhMWNtghuhjNrZnioyK73Cv9uvgCl3tFy8jvddaQw=s64",
      "userId": "04475874712826385383"
     },
     "user_tz": -180
    },
    "id": "UbCUJkvAACjO",
    "outputId": "75cef8b7-2fde-4515-feea-5f141f9464f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data directory is ../data\n"
     ]
    }
   ],
   "source": [
    "# When running on your own computer, you can specify the data directory by:\n",
    "# data_dir = tools.select_data_dir('/your/local/data/directory')\n",
    "data_dir = tools.select_data_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iSkPkzg6ACjW"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "NXLqqAogACje",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "99f956742bb7af044124d3d3c39cf49f",
     "grade": false,
     "grade_id": "cell-4f6ca14d3a2fa27d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    # The models are always evaluated on CPU\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "sClTeHH4ACjl",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e95d5df11dc09d17600373a1afce0e80",
     "grade": false,
     "grade_id": "cell-79a0ef10470c37ba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Data\n",
    "\n",
    "We will use MNIST data in this exercise. Note that we re-scale images so that the pixel intensities are in the range [-1, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "XRpi4qwKACjm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f126cd30854de9a4fcb3648d5d2a530",
     "grade": false,
     "grade_id": "cell-24de0b6a166fd150",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Transform to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Scale to [-1, 1]\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "yjCtDkLGACjs",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "560bf169b73d97af141dc358979a36db",
     "grade": false,
     "grade_id": "cell-511beddf297bf38e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Wasserstein GAN (WGAN)\n",
    "\n",
    "The WGAN value function is constructed as\n",
    "$$\n",
    "  \\min_G \\max_{D \\in \\mathcal{D}} E_{x∼P_r}[D(x)] − E_{\\tilde x∼P_g}[D(\\tilde x)]\n",
    "$$\n",
    "where\n",
    "* the dicriminator $D$ (called critic in WGAN) is constrained to be from the set $\\mathcal{D}$ of 1-Lipschitz functions\n",
    "* $P_r$ is the data distribution\n",
    "* $P_g$ is the model distribution. Samples from the model distribution are produced as follows:\n",
    "\\begin{align}\n",
    "z &\\sim N(0, I)\n",
    "\\\\\n",
    "\\tilde x &= G(z)\n",
    "\\end{align}\n",
    "\n",
    "## Generator\n",
    "\n",
    "Implement the generator in the cell below. We recommend you to use the same architecture of the generator as in Exercise 11.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "OyId2pbJACjs",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33b7265b69d50a1847d4911bdf29ae69",
     "grade": false,
     "grade_id": "Generator",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz, ngf, nc):\n",
    "        \"\"\"WGAN generator.\n",
    "        \n",
    "        Args:\n",
    "          nz:  Number of elements in the latent code.\n",
    "          ngf: Base size (number of channels) of the generator layers.\n",
    "          nc:  Number of channels in the generated images.\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        # YOUR CODE HERE\n",
    "        self.conv1 = nn.ConvTranspose2d(in_channels=nz, out_channels=4*ngf, kernel_size=4, stride=2,padding=1, bias=False)\n",
    "        self.conv2 = nn.ConvTranspose2d(in_channels=4*ngf, out_channels=2*ngf, kernel_size=4, stride=2, bias=False)\n",
    "        self.conv3 = nn.ConvTranspose2d(in_channels=2*ngf, out_channels=ngf, kernel_size=4, stride=2, bias=False)\n",
    "        self.conv4 = nn.ConvTranspose2d(in_channels=ngf, out_channels=nc, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(4*ngf)\n",
    "        self.bn2 = nn.BatchNorm2d(2*ngf)\n",
    "        self.bn3 = nn.BatchNorm2d(ngf)\n",
    "        #raise NotImplementedError()\n",
    "\n",
    "    def forward(self, z, verbose=False):\n",
    "        \"\"\"Generate images by transforming the given noise tensor.\n",
    "        \n",
    "        Args:\n",
    "          z of shape (batch_size, nz, 1, 1): Tensor of noise samples. We use the last two singleton dimensions\n",
    "              so that we can feed z to the generator without reshaping.\n",
    "          verbose (bool): Whether to print intermediate shapes (True) or not (False).\n",
    "        \n",
    "        Returns:\n",
    "          out of shape (batch_size, nc, 28, 28): Generated images.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        z = F.relu(self.bn1(self.conv1(z))) #b,nz,1,1 -> b,4*ngf,2,2\n",
    "#         print(z.shape)\n",
    "        z = F.relu(self.bn2(self.conv2(z))) #b,4*ngf,2,2 -> b,2*ngf,6,6\n",
    "#         print(z.shape)\n",
    "        z = F.relu(self.bn3(self.conv3(z))) #b,2*ngf,6,6 -> b,ngf,14,14\n",
    "#         print(z.shape)\n",
    "        z = torch.tanh(self.conv4(z)) #b,ngf,14,14 -> b,nc,28,28\n",
    "#         print(z.shape)\n",
    "             \n",
    "        return z\n",
    "        #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 991,
     "status": "ok",
     "timestamp": 1590245326780,
     "user": {
      "displayName": "Amit Yadav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhMWNtghuhjNrZnioyK73Cv9uvgCl3tFy8jvddaQw=s64",
      "userId": "04475874712826385383"
     },
     "user_tz": -180
    },
    "id": "yB7PBp13ACjz",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dbdd35dde6a4a659769e03d3ccc51ccd",
     "grade": false,
     "grade_id": "cell-53cda167f289ff2a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "495e4bbe-7e25-4ea6-f37e-04eb8a1737de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_Generator_shapes():\n",
    "    batch_size = 32\n",
    "    nz = 10\n",
    "    netG = Generator(nz, ngf=64, nc=1)\n",
    "\n",
    "    noise = torch.randn(batch_size, nz, 1, 1)\n",
    "    out = netG(noise, verbose=True)\n",
    "\n",
    "    assert out.shape == torch.Size([batch_size, 1, 28, 28]), f\"Bad out.shape: {out.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_Generator_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "aNLafFc9ACj4",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f268c5cd68497f9cfaf76836b6fd1a96",
     "grade": false,
     "grade_id": "cell-f3d7ef6f1dbe76b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Loss for training the generator\n",
    "\n",
    "The generator is trained to minimize the relevant part of the value function using a fixed critic $D$:\n",
    "$$\n",
    "  \\min_G − E_{\\tilde{x} \\sim P_g}[D( \\tilde x)]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "YbJCKymTACj5",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd629acf526825d89f1d66e0d6ad0aeb",
     "grade": false,
     "grade_id": "generator_loss",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generator_loss(D, fake_images):\n",
    "    \"\"\"Loss computed to train the WGAN generator.\n",
    "\n",
    "    Args:\n",
    "      D: The critic whose forward function takes inputs of shape (batch_size, nc, 28, 28)\n",
    "         and produces outputs of shape (batch_size, 1).\n",
    "      fake_images of shape (batch_size, nc, 28, 28): Fake images produces by the generator.\n",
    "\n",
    "    Returns:\n",
    "      loss: The relevant part of the WGAN value function.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    loss = -torch.mean(D(fake_images))\n",
    "    return loss\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "ZYygLln8ACj_",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "555bc0b46f8dcaee9fcc9afd01335248",
     "grade": true,
     "grade_id": "cell-e9f124716144c47d",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell tests generator_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "Ue8pb0pRACkG",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2782b6f5ad7abd2e3bc3cb278d803521",
     "grade": false,
     "grade_id": "cell-34a836a2e901a078",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Critic\n",
    "\n",
    "In WGAN, the discriminator is called a critic because it is not trained to classify.\n",
    "\n",
    "Implement the WGAN critic in the cell below. You can use almost the same architecture as the architecture of the discriminator in Exercise 11.1. The difference is that there is no need to use `sigmoid` nonlinearity in the output layer because the output of the critic does not have to be between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "CUv3-yUhACkH",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ad009dd15fee71cd56b45245e91132f",
     "grade": false,
     "grade_id": "Critic",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, nc=1, ndf=64):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          nc:  Number of channels in the images.\n",
    "          ndf: Base size (number of channels) of the critic layers.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        super(Critic, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(nc, ndf, 4, stride=2, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(ndf, 2*ndf, 4, stride=2, bias=False)\n",
    "        self.conv3 = nn.Conv2d(2*ndf, 4*ndf, 4, stride=2, bias=False)\n",
    "        self.conv4 = nn.Conv2d(4*ndf, nc, 4, stride=2, padding=1, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(ndf)\n",
    "        self.bn2 = nn.BatchNorm2d(2*ndf)\n",
    "        self.bn3 = nn.BatchNorm2d(4*ndf)\n",
    "        \n",
    "        self.l_relu = nn.LeakyReLU(0.2)\n",
    "        #raise NotImplementedError()\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x of shape (batch_size, 1, 28, 28): Images to be evaluated.\n",
    "        \n",
    "        Returns:\n",
    "          out of shape (batch_size,): Critic outputs for images x.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        x = self.l_relu(self.bn1(self.conv1(x))) #b,nc,28,28 -> b,ndf,14,14\n",
    "        x = self.l_relu(self.bn2(self.conv2(x))) #b,ndf,14,14 -> b,2*ndf,6,6\n",
    "        x = self.l_relu(self.bn3(self.conv3(x))) #b,2*ndf,6,6 -> b,4*ndf,2,2\n",
    "        x = self.conv4(x) #b,4*ndf,2,2 -> b,1,1,1\n",
    "        return x.squeeze()\n",
    "        #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 1292,
     "status": "ok",
     "timestamp": 1590245331536,
     "user": {
      "displayName": "Amit Yadav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhMWNtghuhjNrZnioyK73Cv9uvgCl3tFy8jvddaQw=s64",
      "userId": "04475874712826385383"
     },
     "user_tz": -180
    },
    "id": "2NKBEibQACkN",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4df8bd7035d81c82f9729394d8af986b",
     "grade": false,
     "grade_id": "cell-44a2221bdef62f26",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "85200a84-1776-436b-81a0-34c93919de88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_Critic_shapes():\n",
    "    nz = 10  # size of the latent z vector\n",
    "    netD = Critic(nc=1, ndf=64)\n",
    "\n",
    "    batch_size = 32\n",
    "    images = torch.ones(batch_size, 1, 28, 28)\n",
    "    out = netD(images, verbose=True)\n",
    "    assert out.shape == torch.Size([batch_size]), f\"Bad out.shape: {out.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_Critic_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "fRViZb2uACkR",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb329e50f304f424cc95471c499c1b8e",
     "grade": false,
     "grade_id": "cell-162b94410dda3c54",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Loss for training the WGAN critic\n",
    "\n",
    "Recall the value function of WGAN:\n",
    "$$\n",
    "  \\min_G \\max_{D \\in \\mathcal{D}} E_{x∼P_r}[D(x)] − E_{\\tilde x∼P_g}[D(\\tilde x)]\n",
    "$$\n",
    "To tune the critic, we need to minimize the following function:\n",
    "$$\n",
    "  \\min_{D \\in \\mathcal{D}} - E_{x∼P_r}[D(x)] + E_{\\tilde x∼P_g}[D(\\tilde x)]\n",
    "$$\n",
    "You need to implement this loss function *assuming no constraints on D* in the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "bDve79fbACkT",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38efa96a17125ba78bfb3610d67cc315",
     "grade": false,
     "grade_id": "critic_loss",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def critic_loss(critic, real_images, fake_images):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      critic: The critic.\n",
    "      real_images of shape (batch_size, nc, 28, 28): Real images.\n",
    "      fake_images of shape (batch_size, nc, 28, 28): Fake images.\n",
    "\n",
    "    Returns:\n",
    "      loss (scalar tensor): Loss for training the WGAN critic.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    d_fake = critic(fake_images)\n",
    "    d_real = critic(real_images)\n",
    "    loss = torch.mean(d_fake) - torch.mean(d_real) #maximize reward for real, min for fake\n",
    "    return loss\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "bERBpkGPACkY",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1511fac4724c972e04be14c3b860079",
     "grade": true,
     "grade_id": "cell-b697bd01a31143d6",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell tests critic_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "AcIzx894ACkd",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "79ce0f65e782bf812ff1742a8edd45d0",
     "grade": false,
     "grade_id": "cell-c6bf86344f718387",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Without constraints on $D$, the WGAN value function can be made infinitely large. WGAN constrains the derivative of $D$ using a gradient penalty. The penalty is computed at random points between real images and generated ones using the following procedure:\n",
    "* Given a real image $x$ and a fake image $\\tilde x$, draw a random number $\\epsilon \\sim U[0,1]$\n",
    "* $\\hat{x} \\leftarrow \\epsilon x + (1−\\epsilon) \\tilde x$\n",
    "* Compute the gradient penalty $(‖\\nabla_{\\hat{x}} D(\\hat{x})‖_2−1)^2$\n",
    "where $\\nabla_{\\hat{x}} D(\\hat{x})$ is the gradient of $D$ computed at $\\hat{x}$.\n",
    "\n",
    "Your task is to implement the gradient penalty in the cell below. Note that we need to compute the gradient $\\nabla D$ so that we can differentiate through the gradient when computing the derivatives wrt the parameters of the critic. This can be achieved by using function [torch.autograd.grad](https://pytorch.org/docs/stable/autograd.html#torch.autograd.grad) which can create a computational graph with the gradient computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1007,
     "status": "ok",
     "timestamp": 1590245335992,
     "user": {
      "displayName": "Amit Yadav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhMWNtghuhjNrZnioyK73Cv9uvgCl3tFy8jvddaQw=s64",
      "userId": "04475874712826385383"
     },
     "user_tz": -180
    },
    "id": "msGE-cEQACkd",
    "outputId": "ef11e8c4-3110-4762-fbcb-6666fa308a36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.6859)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(10,2,3).norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "VqX8pgNeACki",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f4a7c864f7be3f026fe72d6d9d723726",
     "grade": false,
     "grade_id": "gradient_penalty",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gradient_penalty(critic, real, fake_detached):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      critic: The critic.\n",
    "      real of shape (batch_size, nc, 28, 28): Real images.\n",
    "      fake_detached of shape (batch_size, nc, 28, 28): Fake images (detached from the computational graph).\n",
    "\n",
    "    Returns:\n",
    "      grad_penalty (scalar tensor): Gradient penalty.\n",
    "      x of shape (batch_size, nc, 28, 28): Points x-hat in which the gradient penalty is computed.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    #print(\"iput shape: \", real.shape)\n",
    "    batch_size = real.size(0)\n",
    "    eps = torch.rand(1, device=real.device)\n",
    "    x_cap = eps*real + (1-eps)*fake_detached\n",
    "    x_cap.requires_grad = True\n",
    "    d_out = critic(x_cap)\n",
    "    grads = torch.autograd.grad(outputs=d_out, inputs=x_cap, grad_outputs=torch.ones(d_out.size(), device=real.device), create_graph=True, retain_graph=True)\n",
    "    panelty = ((grads[0].norm(2)-1)**2)\n",
    "    return panelty, x_cap\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 1392,
     "status": "ok",
     "timestamp": 1590245594034,
     "user": {
      "displayName": "Amit Yadav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhMWNtghuhjNrZnioyK73Cv9uvgCl3tFy8jvddaQw=s64",
      "userId": "04475874712826385383"
     },
     "user_tz": -180
    },
    "id": "4YuvZGD1ACkm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d516ab4e1498c3eb557cacc6dfa81cb4",
     "grade": true,
     "grade_id": "test_gradient_penalty",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "72868557-28ca-4112-8168-8df4e89e4883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(729., grad_fn=<PowBackward0>)\n",
      "expected: tensor(729.)\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "tests.test_gradient_penalty(gradient_penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "ZmVXayMYACkq",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "65d2636986e5111dab323b6e18eb5193",
     "grade": false,
     "grade_id": "cell-beafcb4774140942",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Training WGAN-GP\n",
    "\n",
    "We will now train WGAN-GP. To assess the quality of the generated samples, we will use a simple scorer loaded in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 1509,
     "status": "ok",
     "timestamp": 1590245597747,
     "user": {
      "displayName": "Amit Yadav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhMWNtghuhjNrZnioyK73Cv9uvgCl3tFy8jvddaQw=s64",
      "userId": "04475874712826385383"
     },
     "user_tz": -180
    },
    "id": "cci4Y1LiACks",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a7b00448f010b80aa11083d90f6a498",
     "grade": false,
     "grade_id": "cell-3f26ac0c61b87f5d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "6e1c0f40-14d3-489b-9bea-8695babec94e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (drop1): Dropout(p=0.2, inplace=False)\n",
      "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (drop2): Dropout(p=0.2, inplace=False)\n",
      "  (out): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Scorer(\n",
       "  (model): MLP(\n",
       "    (model): Sequential(\n",
       "      (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
       "      (relu1): ReLU()\n",
       "      (drop1): Dropout(p=0.2, inplace=False)\n",
       "      (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (relu2): ReLU()\n",
       "      (drop2): Dropout(p=0.2, inplace=False)\n",
       "      (out): Linear(in_features=256, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scorer import Scorer\n",
    "scorer = Scorer()\n",
    "scorer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "eekWnDOWACkx",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51ea5df8743c88c3519f8b0edd7e1a11",
     "grade": false,
     "grade_id": "cell-b815a01d40637212",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create the network\n",
    "nz = 10\n",
    "netG = Generator(nz=nz, ngf=128, nc=1).to(device)\n",
    "netD = Critic(nc=1, ndf=128).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "9R63t2KZACk0",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b5611be7a320512a966550b548cdef7",
     "grade": false,
     "grade_id": "cell-c11270e33558df93",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Training loop\n",
    "\n",
    "Implement the training loop in the cell below. The recommended hyperparameters:\n",
    "* Optimizer of the critic:    Adam with learning rate 0.0001\n",
    "* Optimizer of the generator: Adam with learning rate 0.0001\n",
    "* Weight $\\lambda=10$ of the gradient penalty term in the discriminator loss:\n",
    "$$\n",
    "  \\min_{D} - E_{x∼P_r}[D(x)] + E_{\\tilde x∼P_g}[D(\\tilde x)]\n",
    "  + \\lambda (‖\\nabla_{\\hat{x}} D(\\hat{x})‖_2−1)^2\n",
    "$$\n",
    "\n",
    "Hints:\n",
    "- We will use the scorer defined above to assess the quality of the generated samples. The desired level of 0.66 should be reached within 15-20 epochs.\n",
    "- You can use the following code to track the training progress. The code plots some generated images and computes the score that we use to evaluate the trained model. Note that the images fed to the scorer need to be normalized to be in the range [0, 1].\n",
    "```\n",
    "with torch.no_grad():\n",
    "    # Plot generated images\n",
    "    z = torch.randn(144, nz, 1, 1, device=device)\n",
    "    samples = netG(z)\n",
    "    tools.plot_generated_samples(samples)\n",
    "    \n",
    "    # Compute score\n",
    "    z = torch.randn(1000, nz, 1, 1, device=device)\n",
    "    samples = netG(z)\n",
    "    samples = (samples + 1) / 2  # Re-normalize to [0, 1]\n",
    "    score = scorer(samples)\n",
    "```\n",
    "- The quality of the images is slightly worse than with the DCGAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1Pc3xR4VzlHxnL8vg2KqQxEJjviFioWGk"
    },
    "colab_type": "code",
    "deletable": false,
    "executionInfo": {
     "elapsed": 4888734,
     "status": "ok",
     "timestamp": 1590251274823,
     "user": {
      "displayName": "Amit Yadav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhMWNtghuhjNrZnioyK73Cv9uvgCl3tFy8jvddaQw=s64",
      "userId": "04475874712826385383"
     },
     "user_tz": -180
    },
    "id": "sa4Wm_kWACk6",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae914389933e3986497ab27451391731",
     "grade": false,
     "grade_id": "training_loop",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "62f3bcc5-ebb4-48af-da6b-1ea0b095aa60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "if not skip_training:\n",
    "    # YOUR CODE HERE\n",
    "    batch_size = iter(trainloader).next()[0].shape[0]\n",
    "    d_optim = torch.optim.Adam(params=netD.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    g_optim = torch.optim.Adam(params=netG.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    \n",
    "    for epoch in range(17):\n",
    "        start = time.time()\n",
    "        running_d_loss = []\n",
    "        running_g_loss = []\n",
    "        for i, (real_images, labels) in enumerate(trainloader):\n",
    "            real_images, labels = real_images.to(device), labels.to(device)\n",
    "            netD.zero_grad()\n",
    "            netD.train()\n",
    "            netG.train()\n",
    "            \n",
    "            #generate fake images\n",
    "            z = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "            fake_images =netG(z).detach()\n",
    "            \n",
    "            #calculate loss\n",
    "            d_loss = critic_loss(netD, real_images, fake_images)\n",
    "            panelty = gradient_penalty(netD, real_images, fake_images)\n",
    "            loss = d_loss + panelty[0]\n",
    "            \n",
    "            #critic step\n",
    "            loss.backward()\n",
    "            d_optim.step()\n",
    "            \n",
    "            #train generator\n",
    "            g_optim.zero_grad()\n",
    "            z = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "            gen_images = netG(z)\n",
    "            g_loss = generator_loss(netD, gen_images)\n",
    "            g_loss.backward()\n",
    "            g_optim.step()\n",
    "\n",
    "            running_d_loss.append(d_loss.item())\n",
    "            running_g_loss.append(g_loss.item())\n",
    "            if i%100==0: print(i, end=\" \")\n",
    "\n",
    "        end = time.time()\n",
    "        print(f\"{epoch} d_loss:{np.mean(running_d_loss)} g_loss:{np.mean(running_g_loss)} time:{end-start}\")\n",
    "        with torch.no_grad():\n",
    "            # Plot generated images\n",
    "            z = torch.randn(144, nz, 1, 1, device=device)\n",
    "            samples = netG(z)\n",
    "            tools.plot_generated_samples(samples)\n",
    "\n",
    "            # Compute score\n",
    "            z = torch.randn(1000, nz, 1, 1, device=device)\n",
    "            samples = netG(z)\n",
    "            samples = (samples + 1) / 2  # Re-normalize to [0, 1]\n",
    "            score = scorer(samples)\n",
    "            print(score)\n",
    "            \n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 37287,
     "status": "ok",
     "timestamp": 1590251312149,
     "user": {
      "displayName": "Amit Yadav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhMWNtghuhjNrZnioyK73Cv9uvgCl3tFy8jvddaQw=s64",
      "userId": "04475874712826385383"
     },
     "user_tz": -180
    },
    "id": "v_FYpEpIACk_",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "148185649c8e8ef649f6be22f2ada708",
     "grade": false,
     "grade_id": "cell-542f62dd494b82be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "86e2abb5-4d18-4184-93ad-37f14d9a92c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to save the model (type yes to confirm)? yes\n",
      "Model saved to 11_wgan_g.pth.\n",
      "Do you want to save the model (type yes to confirm)? yes\n",
      "Model saved to 11_wgan_d.pth.\n"
     ]
    }
   ],
   "source": [
    "# Save the model to disk (the pth-files will be submitted automatically together with your notebook)\n",
    "if not skip_training:\n",
    "    tools.save_model(netG, '11_wgan_g.pth')\n",
    "    tools.save_model(netD, '11_wgan_d.pth')\n",
    "else:\n",
    "    nz = 10\n",
    "    netG = Generator(nz=nz, ngf=128, nc=1)\n",
    "    netD = Critic(nc=1, ndf=128)\n",
    "    \n",
    "    tools.load_model(netG, '11_wgan_g.pth', device)\n",
    "    tools.load_model(netD, '11_wgan_d.pth', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 1727,
     "status": "ok",
     "timestamp": 1590251316491,
     "user": {
      "displayName": "Amit Yadav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhMWNtghuhjNrZnioyK73Cv9uvgCl3tFy8jvddaQw=s64",
      "userId": "04475874712826385383"
     },
     "user_tz": -180
    },
    "id": "94rrZ5wiAClD",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "baf847b91d95961ec044180d0aa10574",
     "grade": true,
     "grade_id": "test_accuracy",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "09def5a6-e2d8-4eb8-dd3b-4b8250b075e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trained WGAN-GP achieves a score of 0.79366\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "# Evaluate generated samples\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(2000, nz, 1, 1, device=device)\n",
    "    samples = (netG(z) + 1) / 2\n",
    "    score = scorer(samples)\n",
    "\n",
    "print(f'The trained WGAN-GP achieves a score of {score:.5f}')\n",
    "assert score >= 0.66, \"Poor GAN score! Check your architecture and training.\"\n",
    "print('Success')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "112_wgan_gp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
