{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "tFvdbG5wLZJX",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e2e3a14a18c67bfc9b0bf7fa9b9dae9",
     "grade": false,
     "grade_id": "cell-3941e0c28ecf711b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Number of points for this notebook:</b> 2\n",
    "<br>\n",
    "<b>Deadline:</b> May 23, 2020 (Saturday) 23:00\n",
    "</div>\n",
    "\n",
    "# Exercise 11.1. Generative adversarial networks (GANs). DCGAN: Deep convolutional GAN\n",
    "\n",
    "The goal of this exercise is to get familiar with generative adversarial networks and specifically DCGAN. The model was proposed by [Radford et al., 2015](https://arxiv.org/pdf/1511.06434.pdf).\n",
    "\n",
    "DCGAN is probably the simplest GAN model which is relatively easy to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6tgEVU5JLZJb"
   },
   "outputs": [],
   "source": [
    "skip_training = True  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "xPE-p621LZJm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3eb0d8430b430162c5ea92d25e5a5061",
     "grade": true,
     "grade_id": "cell-bd68b7386e29d846",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# During evaluation, this cell sets skip_training to True\n",
    "# skip_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xN4a_IA0LZJx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "import tools\n",
    "import tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1685,
     "status": "ok",
     "timestamp": 1590239072591,
     "user": {
      "displayName": "Amit Yadav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhMWNtghuhjNrZnioyK73Cv9uvgCl3tFy8jvddaQw=s64",
      "userId": "04475874712826385383"
     },
     "user_tz": -180
    },
    "id": "xhhnPdJ6LZJ5",
    "outputId": "faf04a5c-7bc3-4ec9-b793-b69578358690"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data directory is ../data\n"
     ]
    }
   ],
   "source": [
    "# When running on your own computer, you can specify the data directory by:\n",
    "# data_dir = tools.select_data_dir('/your/local/data/directory')\n",
    "data_dir = tools.select_data_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tRpGOmq5LZKB"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "E-RiEnooLZKH",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd275621253cd028c5065035e3390f93",
     "grade": false,
     "grade_id": "cell-2212a6a282e966a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    # The models are always evaluated on CPU\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "IWU9r7g-LZKO",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "614e53d08cb3ad04a0db5df92ad20dd6",
     "grade": false,
     "grade_id": "cell-140f604a5cb368f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Data\n",
    "\n",
    "We will use MNIST data in this exercise. Note that we re-scale images so that the pixel intensities are in the range [-1, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "G1EpQbe8LZKQ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b10e7bc7989b4eeb263589646127e559",
     "grade": false,
     "grade_id": "cell-55039c5db5aa5d3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Transform to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Scale images to [-1, 1]\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "\n",
    "batch_size = 100\n",
    "data_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "nTiNXy5fLZKV",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ceff023afd66794411ec51227791aa54",
     "grade": false,
     "grade_id": "cell-797591c879634741",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Generative adversarial networks\n",
    "\n",
    "Our task is to train a generative model of the data, that is a model from which we can draw samples that will have a distribution similar to the distribution of the training data (MNIST digits in our case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "QjB8238dLZKV",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b76f947d1651bf82c003d01b8f14546f",
     "grade": false,
     "grade_id": "cell-9356f4dc68bfdc4e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Generator\n",
    "\n",
    "The generative model that we are going to train is:\n",
    "\\begin{align}\n",
    "z &\\sim N(0, I)\n",
    "\\\\\n",
    "x &= G(z)\n",
    "\\end{align}\n",
    "that is the data is generated by applying a nonlinear transformation to samples drawn from the standard normal distribution.\n",
    "\n",
    "We are going to model $G$ with a deep neural network created below. In DCGAN, the generator is made of only transposed convolutional layers `ConvTranspose2d`.\n",
    "The proposed architecture for the generator:\n",
    "* `ConvTranspose2d` layer with `kernel_size=4`, `stride=2`, `4*ngf` output channels, no bias,\n",
    "   followed by `BatchNorm2d` and ReLU\n",
    "* `ConvTranspose2d` layer with `kernel_size=4`, `stride=2`, `2*ngf` output channels, no bias,\n",
    "   followed by `BatchNorm2d` and ReLU\n",
    "* `ConvTranspose2d` layer with `kernel_size=4`, `stride=2`, `ngf` output channels, no bias,\n",
    "   followed by `BatchNorm2d` and ReLU\n",
    "* `ConvTranspose2d` layer with `kernel_size=4`, `stride=2`, `nc` output channels, no bias,\n",
    "   followed by `tanh`.\n",
    "   \n",
    "The `tanh` nonlinearity guarantees that the output is between -1 and 1 which holds for our scaling of the training data.\n",
    "\n",
    "**The exact architecture is not tested in this assignment. If the description is not full, please fill the missing pieces according to your preferences.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "9TohWdl8LZKW",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a26a1e9624ea328d6bdc50a403e96da4",
     "grade": false,
     "grade_id": "Generator",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz=10, ngf=64, nc=1):\n",
    "        \"\"\"GAN generator.\n",
    "        \n",
    "        Args:\n",
    "          nz:  Number of elements in the latent code.\n",
    "          ngf: Base size (number of channels) of the generator layers.\n",
    "          nc:  Number of channels in the generated images.\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        # YOUR CODE HERE\n",
    "        self.conv1 = nn.ConvTranspose2d(in_channels=nz, out_channels=4*ngf, kernel_size=4, stride=2,padding=1, bias=False)\n",
    "        self.conv2 = nn.ConvTranspose2d(in_channels=4*ngf, out_channels=2*ngf, kernel_size=4, stride=2, bias=False)\n",
    "        self.conv3 = nn.ConvTranspose2d(in_channels=2*ngf, out_channels=ngf, kernel_size=4, stride=2, bias=False)\n",
    "        self.conv4 = nn.ConvTranspose2d(in_channels=ngf, out_channels=nc, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(4*ngf)\n",
    "        self.bn2 = nn.BatchNorm2d(2*ngf)\n",
    "        self.bn3 = nn.BatchNorm2d(ngf)\n",
    "        \n",
    "        #raise NotImplementedError()\n",
    "\n",
    "    def forward(self, z, verbose=False):\n",
    "        \"\"\"Generate images by transforming the given noise tensor.\n",
    "        \n",
    "        Args:\n",
    "          z of shape (batch_size, nz, 1, 1): Tensor of noise samples. We use the last two singleton dimensions\n",
    "                          so that we can feed z to the generator without reshaping.\n",
    "          verbose (bool): Whether to print intermediate shapes (True) or not (False).\n",
    "        \n",
    "        Returns:\n",
    "          out of shape (batch_size, nc, 28, 28): Generated images.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        z = F.relu(self.bn1(self.conv1(z))) #b,nz,1,1 -> b,4*ngf,2,2\n",
    "#         print(z.shape)\n",
    "        z = F.relu(self.bn2(self.conv2(z))) #b,4*ngf,2,2 -> b,2*ngf,6,6\n",
    "#         print(z.shape)\n",
    "        z = F.relu(self.bn3(self.conv3(z))) #b,2*ngf,6,6 -> b,ngf,14,14\n",
    "#         print(z.shape)\n",
    "        z = torch.tanh(self.conv4(z)) #b,ngf,14,14 -> b,nc,28,28\n",
    "#         print(z.shape)\n",
    "             \n",
    "        return z\n",
    "        #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 759,
     "status": "ok",
     "timestamp": 1590240042171,
     "user": {
      "displayName": "Amit Yadav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhMWNtghuhjNrZnioyK73Cv9uvgCl3tFy8jvddaQw=s64",
      "userId": "04475874712826385383"
     },
     "user_tz": -180
    },
    "id": "R8Q_5UFYLZKf",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b80ee06fd8f120e253712503ca8dcbea",
     "grade": false,
     "grade_id": "cell-65fe5c0af77b5d74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "bf7ceb30-0d07-4730-c6e1-5a0cce29f6ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_Generator_shapes():\n",
    "    nz = 10\n",
    "    netG = Generator(nz, ngf=64, nc=1)\n",
    "\n",
    "    batch_size = 32\n",
    "    noise = torch.randn(batch_size, nz, 1, 1)\n",
    "    out = netG(noise, verbose=True)\n",
    "\n",
    "    assert out.shape == torch.Size([batch_size, 1, 28, 28]), f\"Bad shape of out: out.shape={out.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_Generator_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "203Ac-kpLZKl",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ab5a58be5bcef66ea9316f080270a0e9",
     "grade": false,
     "grade_id": "cell-0151d274de94f50d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Loss for training the generator\n",
    "\n",
    "The generative model will be guided by a discriminator whose task is to separate (classify) data into two classes:\n",
    "* true data (samples from the training set)\n",
    "* generated data (samples generated by the generator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "EymBuHDeLZKl",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e539cd126ece05f16aeddabb5953b4e0",
     "grade": false,
     "grade_id": "cell-3f77648eb2fe0ea1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "zFPojFtHLZKs",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4e5d50213a4c91c998d94cb0b248a846",
     "grade": false,
     "grade_id": "cell-7f59b33f30149a9e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The task of the generator is to confuse the discriminator as much as possible, which is the case when the distribution produced by the generator perfectly replicates the data distribution.\n",
    "\n",
    "In the cell below, you need to implement the loss function which is used to train the generator. The loss should be the `binary_cross_entropy` loss computed with `real_label` as targets for the generated samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "aKdIzfPkLZKt",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc4434056403643ab9b5aa40a3fa7e81",
     "grade": false,
     "grade_id": "generator_loss",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generator_loss(D, fake_images):\n",
    "    \"\"\"Loss computed to train the GAN generator.\n",
    "\n",
    "    Args:\n",
    "      D: The discriminator whose forward function takes inputs of shape (batch_size, nc, 28, 28)\n",
    "         and produces outputs of shape (batch_size, 1).\n",
    "      fake_images of shape (batch_size, nc, 28, 28): Fake images produces by the generator.\n",
    "\n",
    "    Returns:\n",
    "      loss: The mean of the binary cross-entropy losses computed for all the samples in the batch.\n",
    "\n",
    "    Notes:\n",
    "    - Make sure that you process on the device given by `fake_images.device`.\n",
    "    - Use values of global variables `real_label`, `fake_label` to produce the right targets.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    criterion = nn.BCELoss()\n",
    "    d_out = D(fake_images)\n",
    "    expected = torch.ones(d_out.size(0), device=fake_images.device)*real_label\n",
    "    loss = criterion(d_out, expected)\n",
    "    return loss\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 982,
     "status": "ok",
     "timestamp": 1590240043642,
     "user": {
      "displayName": "Amit Yadav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhMWNtghuhjNrZnioyK73Cv9uvgCl3tFy8jvddaQw=s64",
      "userId": "04475874712826385383"
     },
     "user_tz": -180
    },
    "id": "qKnR8JfSLZK0",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "896dfc8b029a06075aac748ad8418fa1",
     "grade": true,
     "grade_id": "test_Generator_loss",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "8439b8cf-33e9-401e-c4fa-4acd45406668",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.0730)\n",
      "expected: tensor(1.0730)\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "tests.test_generator_loss(generator_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "_n_iOKPcLZK7",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e19a92777eaac49a9664bc1c029845d1",
     "grade": false,
     "grade_id": "cell-63faa114782d7e87",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Discriminator\n",
    "\n",
    "In DCGAN, the discriminator is a stack of only convolutional layers.\n",
    "\n",
    "The proposed architecture for the discriminator:\n",
    "* `Conv2d` layer with `kernel_size=4`, `stride=2`, `ndf` output channels, no bias,\n",
    "   followed by LeakyReLU(0.2)\n",
    "* `Conv2d` layer with `kernel_size=4`, `stride=2`, `2*ndf` output channels, no bias,\n",
    "   followed by LeakyReLU(0.2)\n",
    "* `Conv2d` layer with `kernel_size=4`, `stride=2`, `4*ndf` output channels, no bias,\n",
    "   followed by LeakyReLU(0.2)\n",
    "* `Conv2d` layer with `kernel_size=4`, `stride=2`, `nc` output channels, no bias,\n",
    "   followed by `sigmoid`.\n",
    "\n",
    "**The exact architecture is not tested in this assignment. If the description is not full, please fill the missing pieces according to your preferences.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "ZtHlOpcCLZK7",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f7aac6360862eb5f3d3fcdae2277ae6",
     "grade": false,
     "grade_id": "Discriminator",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nc=1, ndf=64):\n",
    "        \"\"\"GAN discriminator.\n",
    "        \n",
    "        Args:\n",
    "          nc:  Number of channels in images.\n",
    "          ndf: Base size (number of channels) of the discriminator layers.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(nc, ndf, 4, stride=2, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(ndf, 2*ndf, 4, stride=2, bias=False)\n",
    "        self.conv3 = nn.Conv2d(2*ndf, 4*ndf, 4, stride=2, bias=False)\n",
    "        self.conv4 = nn.Conv2d(4*ndf, nc, 4, stride=2, padding=1, bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(ndf)\n",
    "        self.bn2 = nn.BatchNorm2d(2*ndf)\n",
    "        self.bn3 = nn.BatchNorm2d(4*ndf)\n",
    "        \n",
    "        self.l_relu = nn.LeakyReLU(0.2)\n",
    "        #raise NotImplementedError()\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "        \"\"\"Classify given images into real/fake.\n",
    "        \n",
    "        Args:\n",
    "          x of shape (batch_size, 1, 28, 28): Images to be classified.\n",
    "        \n",
    "        Returns:\n",
    "          out of shape (batch_size,): Probabilities that images are real. All elements should be between 0 and 1.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        x = self.l_relu(self.bn1(self.conv1(x))) #b,nc,28,28 -> b,ndf,14,14\n",
    "        x = self.l_relu(self.bn2(self.conv2(x))) #b,ndf,14,14 -> b,2*ndf,6,6\n",
    "        x = self.l_relu(self.bn3(self.conv3(x))) #b,2*ndf,6,6 -> b,4*ndf,2,2\n",
    "        x = torch.sigmoid(self.conv4(x)) #b,4*ndf,2,2 -> b,1,1,1\n",
    "        return x.squeeze()\n",
    "        \n",
    "        #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 760,
     "status": "ok",
     "timestamp": 1590240045729,
     "user": {
      "displayName": "Amit Yadav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhMWNtghuhjNrZnioyK73Cv9uvgCl3tFy8jvddaQw=s64",
      "userId": "04475874712826385383"
     },
     "user_tz": -180
    },
    "id": "lnj_E4vhLZLC",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc353b6ac051abe22c8f022a7860c348",
     "grade": false,
     "grade_id": "cell-cef1ff3c74404557",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "d4e862af-2668-44eb-b3dd-bf27515ca6a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_Discriminator_shapes():\n",
    "    batch_size = 32\n",
    "    netD = Discriminator(nc=1, ndf=64)\n",
    "\n",
    "    images = torch.ones(32, 1, 28, 28)\n",
    "    out = netD(images, verbose=True)\n",
    "\n",
    "    assert out.shape == torch.Size([batch_size]), f\"Bad shape of out: out.shape={out.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_Discriminator_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "V6fstXPSLZLJ",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cdbd2bd782228ab4f022f52e23ffcd02",
     "grade": false,
     "grade_id": "cell-51681d3003e07996",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Loss for training the discriminator\n",
    "\n",
    "The discriminator is trained to solve a binary classification problem: to separate real data from generated samples. Thus, the output of the discriminator should be a scalar between 0 and 1.\n",
    "\n",
    "You need to implement the loss function used to train the discriminator. The dicriminator uses the `binary_cross_entropy` loss using `real_label` as targets for real samples and `fake_label` as targets for generated samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "3pgSBEjXLZLJ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7021f1d2d4147485b524015beb2284f5",
     "grade": false,
     "grade_id": "discriminator_loss",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(D, real_images, fake_images):\n",
    "    \"\"\"Loss computed to train the GAN discriminator.\n",
    "\n",
    "    Args:\n",
    "      D: The discriminator.\n",
    "      real_images of shape (batch_size, nc, 28, 28): Real images.\n",
    "      fake_images of shape (batch_size, nc, 28, 28): Fake images produces by the generator.\n",
    "\n",
    "    Returns:\n",
    "      d_loss_real: The mean of the binary cross-entropy losses computed on the real_images.\n",
    "      D_real: Mean output of the discriminator for real_images. This is useful for tracking convergence.\n",
    "      d_loss_fake: The mean of the binary cross-entropy losses computed on the fake_images.\n",
    "      D_fake: Mean output of the discriminator for fake_images. This is useful for tracking convergence.\n",
    "\n",
    "    Notes:\n",
    "    - Make sure that you process on the device given by `fake_images.device`.\n",
    "    - Use values of global variables `real_label`, `fake_label` to produce the right targets.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    criterion = nn.BCELoss()\n",
    "    d_fake = D(fake_images)\n",
    "    d_real = D(real_images)\n",
    "    exp_fake = torch.ones(d_fake.size(0), device=fake_images.device)*fake_label\n",
    "    exp_real = torch.ones(d_real.size(0), device=fake_images.device)*real_label\n",
    "    \n",
    "    loss_fake = criterion(d_fake, exp_fake)\n",
    "    loss_real = criterion(d_real, exp_real)\n",
    "    return loss_real, d_real.mean().item(), loss_fake, d_fake.mean().item()\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 1684,
     "status": "ok",
     "timestamp": 1590240048144,
     "user": {
      "displayName": "Amit Yadav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhMWNtghuhjNrZnioyK73Cv9uvgCl3tFy8jvddaQw=s64",
      "userId": "04475874712826385383"
     },
     "user_tz": -180
    },
    "id": "p3G2oHGkLZLP",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd4029769ed532dff0b85dce6a77184c",
     "grade": true,
     "grade_id": "cell-461f1d2ee56f035d",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "ad77d72d-7ba8-4596-813b-9b3ebe3afaaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_discriminator_loss():\n",
    "    netD = Discriminator(nc=1, ndf=64)\n",
    "    real_images = fake_images = torch.ones(32, 1, 28, 28)\n",
    "\n",
    "    d_loss_real, D_real, d_loss_fake, D_fake = discriminator_loss(netD, real_images, fake_images)\n",
    "    assert d_loss_real.shape == torch.Size([]), \"d_loss_real should be a scalar tensor.\"\n",
    "    assert 0 < D_real < 1, \"D_real should be a scalar between 0 and 1.\"\n",
    "    assert d_loss_fake.shape == torch.Size([]), \"d_loss_fake should be a scalar tensor.\"\n",
    "    assert 0 < D_fake < 1, \"D_fake should be a scalar between 0 and 1.\"\n",
    "    print('Success')\n",
    "\n",
    "test_discriminator_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 1573,
     "status": "ok",
     "timestamp": 1590240048145,
     "user": {
      "displayName": "Amit Yadav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhMWNtghuhjNrZnioyK73Cv9uvgCl3tFy8jvddaQw=s64",
      "userId": "04475874712826385383"
     },
     "user_tz": -180
    },
    "id": "WYT_6aBuLZLU",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75d3109b27196a9c4486e072d8aab2a7",
     "grade": true,
     "grade_id": "test_Discriminator_loss",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "22cc9f12-a27e-4a44-c21c-a58de292dae7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_loss_real: tensor(0.3635)\n",
      "expected d_loss_real: tensor(0.3635)\n",
      "D_real: 0.699999988079071\n",
      "expected D_real: 0.699999988079071\n",
      "d_loss_fake: 0.22839301824569702\n",
      "expected d_loss_fake: tensor(0.2284)\n",
      "D_fake: 0.20000000298023224\n",
      "expected D_fake: 0.20000000298023224\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "tests.test_discriminator_loss(discriminator_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "DAOFSLRULZLY",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ac85d9d8c5eba3ee99bb50564ae4f1d",
     "grade": false,
     "grade_id": "cell-619a00b55e2632b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Training GANs\n",
    "\n",
    "We will now train a GAN. To assess the quality of the generated samples, we will use a simple scorer loaded in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 10381,
     "status": "ok",
     "timestamp": 1590240058417,
     "user": {
      "displayName": "Amit Yadav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhMWNtghuhjNrZnioyK73Cv9uvgCl3tFy8jvddaQw=s64",
      "userId": "04475874712826385383"
     },
     "user_tz": -180
    },
    "id": "Fduc7Q4iLZLZ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7718043c3a32bfc96b0a177011c7fd36",
     "grade": false,
     "grade_id": "cell-d79976446847482e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "99cfcdab-f90f-494d-aee8-ccd62778108b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (drop1): Dropout(p=0.2, inplace=False)\n",
      "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (drop2): Dropout(p=0.2, inplace=False)\n",
      "  (out): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Scorer(\n",
       "  (model): MLP(\n",
       "    (model): Sequential(\n",
       "      (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
       "      (relu1): ReLU()\n",
       "      (drop1): Dropout(p=0.2, inplace=False)\n",
       "      (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (relu2): ReLU()\n",
       "      (drop2): Dropout(p=0.2, inplace=False)\n",
       "      (out): Linear(in_features=256, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scorer import Scorer\n",
    "scorer = Scorer()\n",
    "scorer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "CoGFImDQLZLe",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76a80ba0da69e3d29ac875b23c42ba17",
     "grade": false,
     "grade_id": "cell-f306dde125361541",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create the network\n",
    "nz = 10\n",
    "netG = Generator(nz=nz, ngf=64, nc=1)\n",
    "netD = Discriminator(nc=1, ndf=64)\n",
    "\n",
    "netD = netD.to(device)\n",
    "netG = netG.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "rdoS8NwHLZLk",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3d41372a360df901b8a8429a31075f9b",
     "grade": false,
     "grade_id": "cell-e5478e8a7afe65cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Training loop\n",
    "\n",
    "Implement the training loop in the cell below. The recommended hyperparameters:\n",
    "* Optimizer of the discriminator: Adam with learning rate 0.0002 and `betas=(0.5, 0.999)`\n",
    "* Optimizer of the generator:     Adam with learning rate 0.0002 and `betas=(0.5, 0.999)`\n",
    "\n",
    "Hints:\n",
    "- We will use the scorer defined above to assess the quality of the generated samples. The desired level of .7 should be reached within 15-20 epochs.\n",
    "- You can use the following code to track the training progress. The code plots some generated images and computes the score that we use to evaluate the trained model. Note that the images fed to the scorer need to be normalized to be in the range [0, 1].\n",
    "```\n",
    "with torch.no_grad():\n",
    "    # Plot generated images\n",
    "    z = torch.randn(144, nz, 1, 1, device=device)\n",
    "    samples = netG(z)\n",
    "    tools.plot_generated_samples(samples)\n",
    "    \n",
    "    # Compute score\n",
    "    z = torch.randn(1000, nz, 1, 1, device=device)\n",
    "    samples = netG(z)\n",
    "    samples = (samples + 1) / 2  # Re-normalize to [0, 1]\n",
    "    score = scorer(samples)\n",
    "```\n",
    "- The quality of the generated images should be good (better than with the PixelCNN model).\n",
    "- You can track `D_real` and `D_fake` returned by function `discriminator_loss()`. When it is hard for the discriminator to separate real and fake images, their values are close to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G5Y8S1U6LZLl"
   },
   "outputs": [],
   "source": [
    "### plt.imshow(tmp[0].permute(1,2,0), cmap='gray')\n",
    "# transforms.ToPILImage()(tmp[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1yCR5YAWIHXXC1W-hP-H1Qm7Lg4CC7aX4"
    },
    "colab_type": "code",
    "deletable": false,
    "executionInfo": {
     "elapsed": 366330,
     "status": "ok",
     "timestamp": 1590241159604,
     "user": {
      "displayName": "Amit Yadav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhMWNtghuhjNrZnioyK73Cv9uvgCl3tFy8jvddaQw=s64",
      "userId": "04475874712826385383"
     },
     "user_tz": -180
    },
    "id": "Gc2hGim9LZLq",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae914389933e3986497ab27451391731",
     "grade": false,
     "grade_id": "training_loop",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "2f112e3d-5cf0-4be3-e22d-95d1c643bec9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "if not skip_training:\n",
    "    # YOUR CODE HERE\n",
    "    d_optim = torch.optim.Adam(params=netD.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    g_optim = torch.optim.Adam(params=netG.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    for epoch in range(15):\n",
    "        running_d_loss_real = []\n",
    "        running_d_loss_fake = []\n",
    "        running_g_loss = []\n",
    "        running_d_acc_real = []\n",
    "        running_d_acc_fake = []\n",
    "        start = time.time()\n",
    "        for i, (real_images, labels) in enumerate(data_loader):\n",
    "            real_images, labels = real_images.to(device), labels.to(device)\n",
    "            \n",
    "            d_optim.zero_grad()\n",
    "            #g_optim.zero_grad() we need to zero_grad after discriminator step\n",
    "            netD.train()\n",
    "            netG.train()\n",
    "            \n",
    "            #generate fake images\n",
    "            z = torch.randn(100, nz, 1, 1, device=device)\n",
    "            fake_images =netG(z).detach()\n",
    "            \n",
    "            #calculate loss\n",
    "            d_loss_real, mean_real, d_loss_fake, mean_fake = discriminator_loss(netD, real_images, fake_images)\n",
    "            \n",
    "            #train discriminator\n",
    "            d_loss = d_loss_fake + d_loss_real\n",
    "            d_loss.backward()\n",
    "            d_optim.step()\n",
    "            \n",
    "            #train generator\n",
    "            g_optim.zero_grad()\n",
    "            z = torch.randn(100, nz, 1, 1, device=device)\n",
    "            gen_images =netG(z)\n",
    "            g_loss = generator_loss(netD, gen_images)\n",
    "            g_loss.backward()\n",
    "            g_optim.step()\n",
    "            \n",
    "            running_d_loss_real.append(d_loss_real.item())\n",
    "            running_d_loss_fake.append(d_loss_fake.item())\n",
    "            running_d_acc_real.append(mean_real)\n",
    "            running_d_acc_fake.append(mean_fake)\n",
    "            running_g_loss.append(g_loss.item())\n",
    "            if i%100==0: print(i, end=\" \")\n",
    "\n",
    "        end = time.time() \n",
    "        var1, var2, var3, var4, var5 = np.mean(running_d_loss_real), np.mean(running_d_loss_fake), np.mean(running_d_acc_fake), np.mean(running_d_acc_real), np.mean(running_g_loss)\n",
    "        print(f\"\\n{epoch} d_loss_real:{var1} d_loss_fake:{var2} d_acc_fake:{var3} d_acc_real:{var4} g_loss:{var5} time:{end-start}\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "        # Plot generated images\n",
    "          z = torch.randn(144, nz, 1, 1, device=device)\n",
    "          samples = netG(z)\n",
    "          tools.plot_generated_samples(samples)\n",
    "        \n",
    "          # Compute score\n",
    "          z = torch.randn(1000, nz, 1, 1, device=device)\n",
    "          samples = netG(z)\n",
    "          samples = (samples + 1) / 2  # Re-normalize to [0, 1]\n",
    "          score = scorer(samples)\n",
    "          print(\"score:\", score)\n",
    "            \n",
    "            \n",
    "            \n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 368932,
     "status": "ok",
     "timestamp": 1590241171068,
     "user": {
      "displayName": "Amit Yadav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhMWNtghuhjNrZnioyK73Cv9uvgCl3tFy8jvddaQw=s64",
      "userId": "04475874712826385383"
     },
     "user_tz": -180
    },
    "id": "lSRYHYzELZLw",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "665f5dd18c174d0d182750b5a0c0c2b3",
     "grade": false,
     "grade_id": "cell-d7405a9598633d45",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "2fb0ac58-54b5-4ef4-f27e-5a172d27d10c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to save the model (type yes to confirm)? yes\n",
      "Model saved to 11_dcgan_g.pth.\n",
      "Do you want to save the model (type yes to confirm)? yes\n",
      "Model saved to 11_dcgan_d.pth.\n"
     ]
    }
   ],
   "source": [
    "# Save the model to disk (the pth-files will be submitted automatically together with your notebook)\n",
    "if not skip_training:\n",
    "    tools.save_model(netG, '11_dcgan_g.pth')\n",
    "    tools.save_model(netD, '11_dcgan_d.pth')\n",
    "else:\n",
    "    nz = 10\n",
    "    netG = Generator(nz=nz, ngf=64, nc=1)\n",
    "    netD = Discriminator(nc=1, ndf=64)\n",
    "\n",
    "    tools.load_model(netG, '11_dcgan_g.pth', device)\n",
    "    tools.load_model(netD, '11_dcgan_d.pth', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 366906,
     "status": "ok",
     "timestamp": 1590241171071,
     "user": {
      "displayName": "Amit Yadav",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhMWNtghuhjNrZnioyK73Cv9uvgCl3tFy8jvddaQw=s64",
      "userId": "04475874712826385383"
     },
     "user_tz": -180
    },
    "id": "rClaPXkZLZL1",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7b99e40aab2712aed295553b91a86da",
     "grade": true,
     "grade_id": "test_quality",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "c7847622-7719-4483-c29c-11e85a237aa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trained DCGAN achieves a score of 0.71475\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "# Evaluate generated samples\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(1000, nz, 1, 1, device=device)\n",
    "    samples = (netG(z) + 1) / 2\n",
    "    score = scorer(samples)\n",
    "\n",
    "print(f'The trained DCGAN achieves a score of {score:.5f}')\n",
    "assert score >= 0.7, \"Poor GAN score! Check your architecture and training.\"\n",
    "print('Success')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "111_dcgan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
